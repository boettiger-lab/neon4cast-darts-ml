{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405528f7-e5d2-4b98-a47f-78480b326777",
   "metadata": {},
   "source": [
    "# General Residual Error Prediction Object Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b138ccee-46a6-4cbd-aae3-05b63287dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import pandas as pd\n",
    "from darts.models import GaussianProcessFilter\n",
    "from darts import TimeSeries\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from darts.models import BlockRNNModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import smape\n",
    "import ray\n",
    "import os\n",
    "import optuna\n",
    "import argparse\n",
    "\n",
    "class ResidualForecaster():\n",
    "    def __init__(self,\n",
    "                 input_csv_name: str,\n",
    "                 target_variable_column_name: str,\n",
    "                 predicted_target_column_name: str,\n",
    "                 datetime_column_name: str,\n",
    "                 covariates_names: list,\n",
    "                 output_csv_name: str,\n",
    "                 validation_split_date: str, #YYYY-MM-DD\n",
    "                 ):\n",
    "\n",
    "        self.df = pd.read_csv(self.input_csv_name)\n",
    "        self.input_csv_name = input_csv_name\n",
    "        self.target_variable_column_name = target_variable_column_name\n",
    "        self.predicted_target_column_name = predicted_target_column_name\n",
    "        self.datetime_column_name = datetime_column_name\n",
    "        self.covariates_names = covariates_names\n",
    "        self.output_csv_name = output_csv_name\n",
    "        self.validation_split_date = validation_split_name\n",
    "\n",
    "        self._preprocess_data()\n",
    "        self.make_residual_forecasts()\n",
    "    \n",
    "    def make_stitched_series(self, variable_tseries):\n",
    "        \"\"\"\n",
    "        Returns a dictionary {\"variable\": stitched time series of variable}\n",
    "        \"\"\"\n",
    "        kernel = RBF()\n",
    "        \n",
    "        gpf_missing = GaussianProcessFilter(kernel=kernel, \n",
    "                                            alpha=0.001, \n",
    "                                            n_restarts_optimizer=100)\n",
    "        \n",
    "        gpf_missing_big_gaps = GaussianProcessFilter(kernel=kernel, \n",
    "                                                     alpha=2, \n",
    "                                                     n_restarts_optimizer=10)\n",
    "        stitched_series = {}\n",
    "    \n",
    "        # Filtering the TimeSeries\n",
    "        try:\n",
    "            filtered = gpf_missing.filter(variable_tseries, num_samples=500)\n",
    "            filtered_big_gaps = gpf_missing_big_gaps.filter(variable_tseries, \n",
    "                                                            num_samples=500)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "        #if there is a gap over 7 indices, use big gap filter\n",
    "        gap_series = variable_tseries.gaps()\n",
    "        stitched_df = filtered.pd_dataframe()\n",
    "        replacement_df = filtered_big_gaps.pd_dataframe()\n",
    "        \n",
    "        for index, row in gap_series.iterrows():\n",
    "            if row[\"gap_size\"] > 7:\n",
    "                for date in pd.date_range(row[\"gap_start\"], row[\"gap_end\"]):\n",
    "                    stitched_df.loc[date] = replacement_df.loc[date]\n",
    "        \n",
    "        stitched_series = TimeSeries.from_times_and_values(\n",
    "                                    stitched_df.index, \n",
    "                                    stitched_df.values.reshape(\n",
    "                                                len(stitched_df), \n",
    "                                                1, \n",
    "                                                -1))\n",
    "        \n",
    "        return stitched_series\n",
    "        \n",
    "    def _preprocess_data(self):\n",
    "        times = pd.to_datetime(self.df[self.datetime_column_name])\n",
    "        times = pd.DatetimeIndex(times)\n",
    "        variable_list = self.covariates_name + [self.target_variable_column_name,\n",
    "                                                self.predicted_target_column_name]\n",
    "        \n",
    "        var_series_dict = {var: TimeSeries.from_times_and_values(times, \n",
    "                                                                 df[var], \n",
    "                                                                 fill_missing_dates=True,\n",
    "                                                                 freq=\"D\") \n",
    "                                                        for var in variable_list}\n",
    "\n",
    "        stitched_series_dict = {self.make_stitched_series(\n",
    "                                            variable_series_dict[var])\n",
    "                                                    for var in variable_list}\n",
    "        self.inputs = stitched_series_dict[self.target_variable_column_name] - \\\n",
    "                       stitched_series_dict[self.predicted_target_column_name]\n",
    "\n",
    "        self.covariates = stitched_series_dict[self.covariates_names[0]]\n",
    "        for cov_var in self.covariates_names[1:]:\n",
    "            self.covariates.concatenate(stitched_series_dict[cov_var], \n",
    "                                                 axis=1, \n",
    "                                                 ignore_time_axis=True)\n",
    "\n",
    "        # Should add an if statement here for tuning\n",
    "        year = int(self.validation_split_date[:4])\n",
    "        month = int(self.validation_split_date[5:7])\n",
    "        day = int(self.validation_split_date[8:])\n",
    "        split_date = pd.Timestamp(year=year, month=month, day=day)\n",
    "        self.training_set, self.validation_set = inputs.split_before(split_date)\n",
    "\n",
    "\n",
    "\n",
    "    def tune(self):\n",
    "        # Relevant to tuning\n",
    "        def objective(trial):\n",
    "            callback = [PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\n",
    "        \n",
    "            # Hyperparameters\n",
    "            input_chunk_length = trial.suggest_categorical(\"input_chunk_length\", \n",
    "                                                               [31, 60, 180, 356])\n",
    "            kernel_size = trial.suggest_categorical(\"kernel_size\", [2, 3, 5])\n",
    "            num_filters = trial.suggest_categorical(\"num_filters\", [1, 3, 5])\n",
    "            num_layers = trial.suggest_categorical(\"num_layers\", [None, 1, 2, 3])\n",
    "            dilation_base = trial.suggest_categorical(\"dilation_base\", [1, 2, 3])\n",
    "            dropout = trial.suggest_categorical(\"dropout\", [0.1, 0.2, 0.3])\n",
    "        \n",
    "            tcn_model = TCNModel(input_chunk_length=input_chunk_length,\n",
    "                            kernel_size=kernel_size,\n",
    "                            num_filters=num_filters,\n",
    "                            output_chunk_length=30,\n",
    "                            likelihood=QuantileRegression([0.05, 0.1, 0.5, 0.9, 0.95]))\n",
    "        \n",
    "            tcn_model.fit(self.training_set,\n",
    "                          past_covariates=self.covariates,\n",
    "                          epochs=400, \n",
    "                          verbose=False)\n",
    "        \n",
    "            predictions = tcn_model.predict(n=len(self.validation_set[:30]), \n",
    "                                            past_covariates=self.covariates, \n",
    "                                            num_samples=50)\n",
    "            smapes = smape(self.validation_set[:30], predictions, n_jobs=-1, verbose=False)\n",
    "            smape_val = np.mean(smapes)\n",
    "        \n",
    "            return smape_val if smape_val != np.nan else float(\"inf\")\n",
    "\n",
    "\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        \n",
    "        study.optimize(objective, n_trials=10) # Note 10 trials pretty meaningless here\n",
    "        \n",
    "        # We could also have used a command as follows to limit the number of trials instead:\n",
    "        # study.optimize(objective, n_trials=100, callbacks=[print_callback])\n",
    "        \n",
    "        # Finally, print the best value and best hyperparameters:\n",
    "        #print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n",
    "        self.hyperparams = study.best_trial.params\n",
    "\n",
    "    def make_residual_forecasts(self):\n",
    "        tcn = TCNModel(input_chunk_length=35,\n",
    "               output_chunk_length=34,\n",
    "               likelihood=QuantileRegression([0.05, 0.1, 0.5, 0.9, 0.95]),\n",
    "               random_state=0)\n",
    "    \n",
    "        tcn.fit(training_set,\n",
    "                past_covariates=covs,\n",
    "                epochs=500, \n",
    "                verbose=False)\n",
    "\n",
    "        predictions = tcn.predict(n=34,\n",
    "                                  past_covariates=covs, \n",
    "                                  num_samples=500)\n",
    "\n",
    "        predictions.pd_dataframe().to_csv(self.output_csv_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09587312-023b-4eab-a6a0-c1f5ed58eb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
