{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef4ffe7-f982-45f2-b3fe-029f781066f3",
   "metadata": {},
   "source": [
    "# Global RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031219a-77cc-4db4-ba03-c03a6912d7fb",
   "metadata": {},
   "source": [
    "In this notebook, I train a single ML model across sites and across target variables -- i.e. a global model. Darts syntax makes this task, at first glance, easier than the alternative, to train models for every target variable at every site individually. This is because all you have to do to train a global model is input a list of all the target variables and covariates to the Darts model, but this requires a bit more preprocessing, which is what most of this notebook is dedicated to. I will throw the pre-processing tidbits into utils when I have the chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60733bfd-701c-42ac-af2b-5b9596ee2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import (\n",
    "    make_stitched_series,\n",
    "    get_variable_dataframes,\n",
    "    global_model_preprocess,\n",
    "    train_local_models, \n",
    "    train_global_model,\n",
    "    make_plot_global,\n",
    "    make_plot_global_long_horizon,\n",
    "    make_plot_local\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import ray \n",
    "from darts.models import BlockRNNModel\n",
    "from darts.utils.likelihood_models import LaplaceLikelihood\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "targets = pd.read_csv(\"aquatics-targets.csv.gz\")\n",
    "# Maybe put ray.init call somehwhere here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f424b9f-ef8c-4d3b-8f12-51eaeb1f6b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>site_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>ARIK</td>\n",
       "      <td>chla</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-05</td>\n",
       "      <td>ARIK</td>\n",
       "      <td>oxygen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>ARIK</td>\n",
       "      <td>chla</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>ARIK</td>\n",
       "      <td>oxygen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>ARIK</td>\n",
       "      <td>chla</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime site_id variable  observation\n",
       "0  2016-03-05    ARIK     chla          NaN\n",
       "1  2016-03-05    ARIK   oxygen          NaN\n",
       "2  2016-03-06    ARIK     chla          NaN\n",
       "3  2016-03-06    ARIK   oxygen          NaN\n",
       "4  2016-03-07    ARIK     chla          NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528ff72-8987-4b94-8f6f-2baf857dafab",
   "metadata": {},
   "source": [
    "In the next 3 cells, I do a bit of preprocessing. In the first cell, I create DataFrames of the target variables for each site, such that all the target variable time series will share a common time index. Then, in the second cell, I perform bespoke filtering, where I fit 2 Gaussian Process Filters and stitch them together. This is to account for there being big and small gaps in the data, and one GP filter didn't seem to account well for both of these gaps. I do this latter task using Ray to parallelize the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace4dfff-c7bd-4a52-a581-b80395696c8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n",
      "/home/rstudio/neon4cast-darts/utils.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  variable_df_dict[variable] = targets[targets.site_id == site][\n"
     ]
    }
   ],
   "source": [
    "site_dicts = [get_variable_dataframes(site, targets) \n",
    "                      for site in targets[\"site_id\"].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41de1aa-52d4-4728-bb57-4936948604cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:24:45,055\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255404)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255404)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255404)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255404)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255404)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255404)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255487)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255487)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255500)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255482)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255487)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255500)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255500)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255502)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255482)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255502)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255502)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255500)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255500)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255509)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255360)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255418)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255494)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255486)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255482)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255502)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255509)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255505)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255497)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255503)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255477)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255477)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255363)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255506)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255505)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255356)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255485)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255360)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255492)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255497)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255485)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255431)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255357)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255356)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255490)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255491)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255511)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255510)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255507)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255366)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255431)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255504)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255512)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255498)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255501)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255499)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255357)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255504)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255478)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255510)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m /home/rstudio/.local/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m \n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m     https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m   _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n",
      "\u001b[2m\u001b[36m(make_stitched_series pid=1255508)\u001b[0m You are transforming a stochastic TimeSeries (i.e., contains several samples). The resulting DataFrame is a 2D object with all samples on the columns. If this is not the expected behavior consider calling a function adapted to stochastic TimeSeries like quantile_df().\n"
     ]
    }
   ],
   "source": [
    "stitched_series_list = [make_stitched_series.remote(site_dict) for site_dict in site_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac7e7ea8-9269-40e0-88d4-b9498a8cc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = ray.get(stitched_series_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbedc2a-a249-428d-a5c5-214b7b1c3231",
   "metadata": {},
   "source": [
    "Now doing the preprocessing which I just throw into utils. This creates lists of the inputs, their corresponding validation sets and the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "92aaaaf4-dfb4-405f-90c7-72c24ca663d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError: Timestamp must be between 2017-08-26 00:00:00 and 2022-09-20 00:00:00\n",
      "ValueError: Timestamp must be between 2017-08-26 00:00:00 and 2022-09-20 00:00:00\n",
      "ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "inputs, val_set, cov_set = global_model_preprocess(targets, named_ts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b024cb-8332-41ab-84c8-5b261eacbbf5",
   "metadata": {},
   "source": [
    "Now, I train the model. This takes a long time, so skip to loading cell to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7741d55a-6076-462a-8f32-d57ccc8fbaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlockRNNModel(model=LSTM, hidden_dim=256, n_rnn_layers=3, hidden_fc_sizes=None, dropout=0.0, batch_size=8, input_chunk_length=15, output_chunk_length=34, likelihood=<darts.utils.likelihood_models.LaplaceLikelihood object at 0x7fc0304c3fa0>, optimizer_kwargs={'lr': 0.0001}, random_state=0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_rnn_ = train_global_model.remote(inputs, cov_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017ca29-0f91-4b02-923b-efab50f71982",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rnn = ray.get(global_rnn_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a45a79-7604-4be9-81c9-4ffa53eefc3a",
   "metadata": {},
   "source": [
    "Saving the model as it took a very long time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "666f2e8e-8e5d-42ef-819a-b9c7c7662ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rnn.save(\"global_block_rnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a5690-6ba1-4268-8a8c-9fc83ef123ad",
   "metadata": {},
   "source": [
    "Loading,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f38ceb68-7814-4980-a9bb-1d8c1151d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_loaded = BlockRNNModel.load(\"global_block_rnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a23fb3-2548-4daf-936b-e20560e8dc30",
   "metadata": {},
   "source": [
    "Now, plotting some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5396afe3-7ad7-462c-9b01-0c37ecad566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38631bf6794f41fc8745f398fe1ba02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot_long_horizon(rnn_loaded, inputs, 2, cov_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "99d933e0-b582-4552-b3ac-e37904ecf2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fb84e8eb364379851256214d783672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(rnn_loaded, inputs, 2, cov_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915db040-8277-4e96-92ad-dd7f3e3c3124",
   "metadata": {},
   "source": [
    "## Now training individual models on each site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33505299-440f-401b-a0ad-830d0a6c0cb2",
   "metadata": {},
   "source": [
    "Initially, just training one model on one site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c99d32f8-5001-40bc-bb77-dc7471205464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    }
   ],
   "source": [
    "site_models_dict = {site : {} for site in targets[\"site_id\"].unique()}\n",
    "train_local_model(\"ARIK\", named_ts_dict, site_models_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356e4da-803f-4ef9-8d32-28501554f7fd",
   "metadata": {},
   "source": [
    "This code cell will train on all the sites and their corresponding target variables. Note, this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02beedf6-3119-47ba-a16b-f560ba2c1764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "individual_models_list = [train_local_model(site, named_ts_dict, site_models_dict) \n",
    "                              for site in targets[\"site_id\"].unique()]\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "for site in targets[\"site_id\"].unique():\n",
    "    for variable in [\"oxygen\", \"temperature\", \"chla\"]:\n",
    "        try:\n",
    "            model = site_models_dict[site][variable][0]\n",
    "            model.save(f\"models/local_{site}_{variable}.pt\")\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5fab5ae8-4ca3-4ab4-b827-3267fc23986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4a783e48474e0f9db4c4071e75517d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot_local(\"ARIK\", \"temperature\", site_models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "de51fbec-baa6-489c-b69a-66ab8d2701f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1599074)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599074)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599074)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599074)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599332)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1599332)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1599332)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599332)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 16:58:10,980 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1599210)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599210)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599210)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599210)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599680)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599680)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599680)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599680)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599666)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1599666)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1599666)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599666)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1599998)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599998)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599998)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599998)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1599998)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 16:59:10,981 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1600267)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1600267)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1600267)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600267)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1600329)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1600329)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1600329)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1600329)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1600208)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600778)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600778)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600778)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600778)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600717)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1600717)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1600717)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1600717)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1601054)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601054)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601054)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601054)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:00:12,628 E 1255234 1255234] (raylet) node_manager.cc:3069: 13 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1601311)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601311)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601311)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601311)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1601311)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1601206)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1601206)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1601206)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1601206)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1601570)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1601570)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1601570)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1601570)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:01:12,631 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1601206)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1602025)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602025)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602025)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602025)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602352)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602352)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602352)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602352)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1602231)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1602231)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1602231)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1602231)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1602231)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:02:12,633 E 1255234 1255234] (raylet) node_manager.cc:3069: 15 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1602995)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1602995)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1602995)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1602995)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1603201)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1603201)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1603201)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1603201)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1603201)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1603323)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1603323)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1603323)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1603323)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1603261)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1603261)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1603261)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1603261)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:03:12,635 E 1255234 1255234] (raylet) node_manager.cc:3069: 15 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1603968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1603968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1603968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1603968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604028)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1604028)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1604028)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604028)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604356)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604356)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604356)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604356)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604233)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1604233)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1604233)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604233)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:04:12,941 E 1255234 1255234] (raylet) node_manager.cc:3069: 6 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1604233)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1604173)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1604173)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1604173)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1604173)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1604173)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1604434)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1604434)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1604434)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1604434)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:05:12,943 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1605160)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1605160)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1605160)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1605160)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1605160)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1605281)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1605281)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1605281)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1605281)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1605174)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1605174)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1605174)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1605174)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1605174)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1605626)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1605626)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1605626)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1605626)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606005)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606005)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606005)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606005)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606005)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1606065)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1606065)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1606065)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1606065)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:06:12,946 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1606219)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1606219)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1606219)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606219)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606065)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606405)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606405)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606405)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606405)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606219)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1606285)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1606285)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1606285)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606285)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1606490)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606490)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606490)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606490)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1606285)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1607053)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607053)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607053)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607053)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607066)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1607066)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1607066)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607066)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:07:13,834 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1607053)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1607211)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1607211)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1607211)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607211)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607333)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1607333)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1607333)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1607333)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1607211)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1607529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607271)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607530)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1607530)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1607530)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1607530)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:08:13,835 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1608038)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608038)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608038)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608038)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608193)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608193)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608193)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608193)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1608193)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:09:16,223 E 1255234 1255234] (raylet) node_manager.cc:3069: 9 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1608635)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1608635)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1608635)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1608635)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1609025)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1609025)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1609025)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1609025)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1609173)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1609173)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1609173)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1609173)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1609173)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:10:16,225 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1609558)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1609558)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1609558)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1609558)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610055)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610055)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610055)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610055)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610326)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610326)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610326)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610326)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610326)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1610388)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610388)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610388)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1610388)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2023-06-18 17:11:44,729\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-06-18 17:11:44,734\tWARNING worker.py:2019 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 93bf13cb03e181df405e8a4cf540c31498bf5ba501000000 Worker ID: 2904180164c7381bda9c100b0593ab42c6d6fde09aa439f90336f34c Node ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce Worker IP address: 172.18.0.16 Worker port: 35409 Worker PID: 1584567 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:11:44,714 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1610206)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1610388)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1610266)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1610266)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1610266)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610266)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610540)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610540)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610540)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610540)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610266)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:12:44,716 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1611743)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1611743)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1611743)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1611743)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1611743)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1611924)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1611924)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1611924)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1611924)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1611757)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1611757)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1611757)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1611757)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:13:44,718 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1611924)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612098)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612098)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612098)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612098)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612285)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1612285)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1612285)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612285)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612098)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612037)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612037)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612037)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612037)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612159)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1612159)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1612159)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612159)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1612037)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612687)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612687)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612687)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612687)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612687)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1612748)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1612748)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1612748)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612748)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:14:44,728 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1613094)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613094)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613094)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613094)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612968)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1612968)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1612968)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1612968)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1613035)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1613035)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1613035)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1613035)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1613219)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1613219)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1613219)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613219)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613035)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:15:45,260 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1613868)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613868)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613868)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613868)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613806)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1613806)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1613806)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1613806)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614151)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614151)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614151)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614151)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614090)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1614090)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1614090)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614090)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614596)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614596)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614596)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614596)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1572588)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1614596)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:16:47,492 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1572588)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1572588)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1572588)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1572588)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1574375)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1574375)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614734)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614734)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614734)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614734)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1614734)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1614807)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1614807)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1614807)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614807)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614951)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614951)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614951)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1614951)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615012)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1615012)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1615012)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615012)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1615328)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1615328)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1615328)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615328)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1580621)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:17:47,493 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1615547)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1615547)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1615547)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615547)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615697)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1615697)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1615697)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1615697)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:18:47,496 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1616203)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616203)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616203)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616203)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616268)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1616268)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1616268)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616268)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616409)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616409)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616409)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616409)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616546)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1616546)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1616546)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616546)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616618)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616618)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616618)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616618)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616678)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1616678)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1616678)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1616678)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:19:47,497 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1578476)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1616869)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1616869)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1616869)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1616869)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1560961)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1578476)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1578476)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1578476)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578476)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578476)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1617086)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1617086)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1617086)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1617086)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1560961)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1617455)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1617455)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1617455)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1617455)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:20:49,635 E 1255234 1255234] (raylet) node_manager.cc:3069: 8 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1617529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1617529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1617529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1617529)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618048)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1618048)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1618048)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618048)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618311)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618311)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618311)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618311)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:21:49,638 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1618446)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618446)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618446)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618446)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618461)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1618461)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1618461)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618461)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618446)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1579818)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1618840)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1618840)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1618840)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1618840)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1579818)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1618903)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618903)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618903)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618903)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1618840)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:22:49,639 E 1255234 1255234] (raylet) node_manager.cc:3069: 13 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1619177)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1619177)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1619177)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1619177)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1619177)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1619697)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1619697)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1619697)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1619697)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:23:52,082 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1619765)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1619765)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1619765)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1619765)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1619697)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1620028)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620028)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620028)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620028)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620090)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1620090)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1620090)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620090)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620237)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620237)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620237)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620237)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620170)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1620170)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1620170)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620170)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:24:52,083 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1620563)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620563)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620563)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620563)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620690)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1620690)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1620690)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620690)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620563)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1620888)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620888)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620888)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620888)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1620888)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1621065)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1621065)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1621065)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621065)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:25:52,085 E 1255234 1255234] (raylet) node_manager.cc:3069: 13 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1621453)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1621453)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1621453)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1621453)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1621777)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621777)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621777)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621777)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621837)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1621837)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1621837)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621837)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:26:52,086 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1621975)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621975)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621975)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1621975)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622306)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1622306)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1622306)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622306)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622306)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1622493)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1622493)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1622493)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622493)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622636)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1622636)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1622636)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1622636)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:27:52,087 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1623017)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623017)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623017)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623017)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622951)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1622951)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1622951)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1622951)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623161)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623161)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623161)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623161)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623229)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1623229)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1623229)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623229)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:28:54,611 E 1255234 1255234] (raylet) node_manager.cc:3069: 9 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1623493)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623493)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623493)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623493)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623493)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1623808)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1623808)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1623808)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623808)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623884)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623884)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623884)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623884)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1623884)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1624029)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1624029)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1624029)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1624029)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:29:54,614 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1624351)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1624351)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1624351)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1624351)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1624980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1624980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1624980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1624980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1624790)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1624790)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1624790)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1624790)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:30:59,585 E 1255234 1255234] (raylet) node_manager.cc:3069: 8 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1624790)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1624851)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1624851)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1624851)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1624851)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1625308)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1625308)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1625308)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625308)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:31:59,587 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1625714)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1625714)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1625714)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625714)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625774)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1625774)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1625774)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1625774)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1625774)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1626159)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1626159)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1626159)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626159)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1625714)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626489)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626489)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626489)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626489)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:32:59,589 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1626564)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1626564)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1626564)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626564)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1626950)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1626950)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1626950)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1626950)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1584941)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1584941)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1627024)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1627024)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1627024)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1627024)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:33:59,592 E 1255234 1255234] (raylet) node_manager.cc:3069: 13 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1627357)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627357)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627357)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627357)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627425)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1627425)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1627425)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627425)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627559)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627559)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627559)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627559)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627697)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1627697)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1627697)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627697)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627712)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627712)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627712)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627712)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1627697)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:35:00,726 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1628217)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1628217)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1628217)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1628217)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1628516)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1628516)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1628516)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1628516)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:36:00,764 E 1255234 1255234] (raylet) node_manager.cc:3069: 9 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1628712)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1628712)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1628712)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1628712)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629047)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629047)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629047)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629047)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629033)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629033)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629033)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629033)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:37:00,766 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1629435)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1629435)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1629435)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629435)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629700)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629700)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629700)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629700)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1629960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1629960)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630020)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1630020)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1630020)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630020)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:38:00,768 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1630228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630153)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1630153)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1630153)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630153)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630424)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630424)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630424)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630424)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630810)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1630810)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1630810)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1630810)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:39:00,770 E 1255234 1255234] (raylet) node_manager.cc:3069: 13 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1631144)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631144)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631144)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631144)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631402)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631402)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631402)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631402)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1631402)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1631342)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1631342)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1631342)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631342)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631730)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631730)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631730)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631730)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631666)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1631666)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1631666)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631666)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:40:00,771 E 1255234 1255234] (raylet) node_manager.cc:3069: 12 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1631881)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631881)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631881)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631881)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632004)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1632004)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1632004)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632004)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631881)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1631942)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631942)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631942)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1631942)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632434)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1632434)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1632434)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632434)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:41:00,773 E 1255234 1255234] (raylet) node_manager.cc:3069: 11 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1632636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632569)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1632569)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1632569)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632569)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632781)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632781)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632781)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632781)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632911)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1632911)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1632911)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1632911)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:42:00,785 E 1255234 1255234] (raylet) node_manager.cc:3069: 13 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1633491)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633491)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633491)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633491)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633692)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633692)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633692)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633692)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633893)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633893)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633893)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1633893)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:43:04,108 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1633893)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1633908)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1633908)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1633908)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1633908)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634278)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634278)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634278)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634278)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634345)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1634345)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1634345)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634345)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634535)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634535)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634535)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634535)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634475)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1634475)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1634475)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634475)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1634684)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1634684)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1634684)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1634684)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:44:04,109 E 1255234 1255234] (raylet) node_manager.cc:3069: 15 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1635241)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635241)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635241)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635241)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635121)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1635121)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1635121)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635121)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635449)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635449)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635449)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635449)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635647)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635647)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635647)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635647)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1635838)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635838)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635838)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635838)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635777)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1635777)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1635777)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635777)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:45:04,110 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1635972)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635972)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635972)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635972)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1636036)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1636036)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1636036)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1636036)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1635972)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1636304)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1636304)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1636304)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1636304)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1636304)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1582719)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637133)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637133)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637133)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637133)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1637204)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1637204)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1637204)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637204)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:46:04,886 E 1255234 1255234] (raylet) node_manager.cc:3069: 20 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637587)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637587)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637587)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637587)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637525)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1637525)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1637525)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637525)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1573136)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637788)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1637788)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1637788)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637788)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637726)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637883)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637883)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637883)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637883)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637882)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1637882)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1637882)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637882)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:47:05,499 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637882)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1638644)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1638644)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1638644)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638644)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638779)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1638779)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1638779)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1638779)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1638925)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638925)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638925)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638925)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638859)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1638859)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1638859)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638859)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:48:05,502 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1638997)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638997)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638997)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1638997)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639563)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1639563)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1639563)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639563)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1579631)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1639815)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639815)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639815)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639815)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:49:05,503 E 1255234 1255234] (raylet) node_manager.cc:3069: 14 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1640118)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1640118)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1640118)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640118)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640317)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1640317)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1640317)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1640317)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1640454)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640454)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640454)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640454)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640591)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1640591)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1640591)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640591)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:50:05,505 E 1255234 1255234] (raylet) node_manager.cc:3069: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1640735)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640735)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640735)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1640735)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1642090)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1642090)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1642090)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1642090)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1642177)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642177)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642177)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642177)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642428)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1642428)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1642428)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642428)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1578372)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:53:12,042 E 1255234 1255234] (raylet) node_manager.cc:3069: 8 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1642605)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1642605)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1642605)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642605)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1642814)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642814)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642814)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642814)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:54:12,045 E 1255234 1255234] (raylet) node_manager.cc:3069: 6 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1643015)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1643015)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1643015)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643015)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610206)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1643106)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1643106)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1643106)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643106)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1610206)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1643300)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1643300)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1643300)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1643300)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:55:12,047 E 1255234 1255234] (raylet) node_manager.cc:3069: 6 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1643429)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643429)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643429)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643429)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643505)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1643505)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1643505)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643505)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643819)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643819)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643819)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1643819)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:56:12,049 E 1255234 1255234] (raylet) node_manager.cc:3069: 6 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1644014)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1644014)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1644014)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644014)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644222)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1644222)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1644222)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644222)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 17:57:12,050 E 1255234 1255234] (raylet) node_manager.cc:3069: 6 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1644494)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1644494)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1644494)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644494)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645432)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1645432)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1645432)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645432)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:00:13,207 E 1255234 1255234] (raylet) node_manager.cc:3069: 4 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1560961)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1645845)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1645845)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1645845)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645845)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645985)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645985)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645985)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645985)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645923)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1645923)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1645923)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645923)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:01:13,208 E 1255234 1255234] (raylet) node_manager.cc:3069: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646071)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646071)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646071)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646071)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646213)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646213)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646213)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646213)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646286)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646286)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646286)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646286)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:02:13,210 E 1255234 1255234] (raylet) node_manager.cc:3069: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1579818)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1584566)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646636)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646636)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646636)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:03:14,304 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:04:14,306 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1580130)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646935)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646935)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646935)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646935)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:05:14,308 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1647134)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1647134)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1647134)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647134)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:06:14,309 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1647474)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647474)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647474)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647474)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:07:14,312 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1647648)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1647648)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1647648)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647648)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:08:14,313 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1647823)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647823)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647823)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647823)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:09:14,314 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1647993)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1647993)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1647993)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1647993)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:10:14,315 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1648210)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648210)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648210)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648210)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:11:14,317 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1648444)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1648444)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1648444)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648444)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:12:14,319 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1648558)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1648558)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1648558)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1648558)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:14:14,323 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1648731)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648731)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648731)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648731)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:15:14,324 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1648905)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1648905)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1648905)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1648905)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:16:14,325 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1649150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649150)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:17:14,327 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1649324)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1649324)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1649324)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649324)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:18:14,329 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1649497)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649497)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649497)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649497)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:19:14,330 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1649673)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1649673)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1649673)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649673)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:20:14,333 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:21:15,216 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1649887)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649887)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649887)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1649887)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:22:15,217 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1650067)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1650067)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1650067)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650067)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650135)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650135)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650135)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650135)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1584941)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:23:15,218 E 1255234 1255234] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1650348)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1650348)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1650348)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650348)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:24:15,231 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1650465)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650465)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650465)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650465)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:25:15,232 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1650624)\u001b[0m GPU available: True (cuda), used: True\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1650624)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1650624)\u001b[0m IPU available: False, using: 0 IPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1650624)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:27:15,235 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1650745)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650745)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650745)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650745)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:28:15,236 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1650862)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1650862)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1650862)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650862)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:29:15,237 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1650980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650980)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:30:15,240 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:31:15,241 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1651255)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1651255)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1651255)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1651255)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:32:15,242 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:33:15,390 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:35:15,393 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:36:15,395 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-06-18 18:37:15,398 E 1255234 1255234] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 6d5a2fd4de2f1df2432abc1197355b9b0df74f1cfc4552e1b9ace7ce, IP: 172.18.0.16) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.18.0.16`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[36m(train_models pid=1610206)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641901)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1615267)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637034)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1646544)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1637661)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1645581)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1644662)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1646482)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1650267)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1641701)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_models pid=1646873)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1639377)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1642545)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1651839)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1655204)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1656228)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1656857)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1657817)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1658446)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1659169)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1660010)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1660756)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1661524)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1662499)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1663189)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1664045)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1664778)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1665470)\u001b[0m ValueError: Timestamp must be between 2017-08-26 00:00:00 and 2022-09-20 00:00:00\n",
      "\u001b[2m\u001b[36m(train_models pid=1665470)\u001b[0m ValueError: Timestamp must be between 2017-08-26 00:00:00 and 2022-09-20 00:00:00\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1665568)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1666427)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1667164)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1668047)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1668968)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "ValueError: Timestamp must be between 2017-08-26 00:00:00 and 2022-09-20 00:00:00\n",
      "ValueError: Timestamp must be between 2017-08-26 00:00:00 and 2022-09-20 00:00:00\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1669594)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1670633)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1671323)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1671896)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1672782)\u001b[0m ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "\u001b[2m\u001b[36m(train_models pid=1672782)\u001b[0m ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "\u001b[2m\u001b[36m(train_models pid=1672782)\u001b[0m ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1672877)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1673716)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1674463)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(train_models pid=1675382)\u001b[0m `Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "ValueError: Timestamp must be between 2018-08-17 00:00:00 and 2022-09-30 00:00:00\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    }
   ],
   "source": [
    "individual_models_list = [train_local_model(site, named_ts_dict, site_models_dict) \n",
    "                              for site in targets[\"site_id\"].unique()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
